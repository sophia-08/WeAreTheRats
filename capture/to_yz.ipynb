{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabaf7a-b620-4398-ad21-529b876bfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "# !apt-get -qq install xxd\n",
    "# !pip3 install pandas numpy matplotlib\n",
    "# !pip3 install tensorflow==2.13.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c351ed4-1f47-4af3-8fa2-84a9286932a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "filename = \"a_h.csv\"\n",
    "\n",
    "num_samples = 150\n",
    "timeInterval = 1.0/num_samples\n",
    "\n",
    "rows=3\n",
    "columns=4\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "fig, ax = plt.subplots(rows,columns)\n",
    "dxll=[]\n",
    "dyll=[]\n",
    "dzll=[]\n",
    "vxll = []\n",
    "vyll = []\n",
    "vzll = []\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        print(\"r=\",r, \"c=\",c)\n",
    "        ch = r*columns + c\n",
    "        start = 0+num_samples*ch\n",
    "        stop = num_samples*(ch+1)\n",
    "        samples = stop - start\n",
    "        df = pd.read_csv(\"./content/\" + filename)\n",
    "        # df = df.loc[range(start, stop)]\n",
    "        index = range(samples)\n",
    "\n",
    "        vx=0\n",
    "        vy=0\n",
    "        vz=0\n",
    "        vx_list = []\n",
    "        vy_list = []\n",
    "        vz_list = []\n",
    "        for i in range(start, stop):\n",
    "            # vx -= (df['aX'][i]-df['aX'][start])*timeInterval\n",
    "            # vy -= (df['aY'][i]-df['aY'][start])*timeInterval\n",
    "            # vz += (df['aZ'][i]-df['aZ'][start])*timeInterval            \n",
    "       \n",
    "            vx -= (df['aX'][i])*timeInterval\n",
    "            vy -= (df['aY'][i])*timeInterval                 \n",
    "            vz += (df['aZ'][i])*timeInterval            \n",
    "            vx_list.append(vx)\n",
    "            vy_list.append(vy)\n",
    "            vz_list.append(vz)\n",
    "\n",
    "        vxll.append(vx_list[:])\n",
    "        vyll.append(vy_list[:])\n",
    "        vzll.append(vz_list[:])            \n",
    "\n",
    "        dx=0\n",
    "        dy=0\n",
    "        dz=0\n",
    "        dx_list = []\n",
    "        dy_list = []\n",
    "        dz_list = []\n",
    "        for i in range(0, stop-start):\n",
    "            dx += vx_list[i]*timeInterval\n",
    "            dx_list.append(dx)\n",
    "            dy += vy_list[i]*timeInterval\n",
    "            dy_list.append(dy)\n",
    "            dz += vz_list[i]*timeInterval\n",
    "            dz_list.append(dz)\n",
    "        \n",
    "        dxll.append(dx_list[:])\n",
    "        dyll.append(dy_list[:])\n",
    "        dzll.append(dz_list[:])\n",
    "\n",
    "\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        # xi = dyll[r*columns+c]\n",
    "        # xj = dzll[r*columns+c]\n",
    "        # print(xi, \" \" , xj)\n",
    "        # ax[r,c].plot(vxll[r*columns+c], label='x')\n",
    "        # ax[r,c].plot(vyll[r*columns+c], label='y')\n",
    "        # ax[r,c].plot(vzll[r*columns+c], label='z')\n",
    "        # ax[r,c].legend()\n",
    "        # ax[r,c].scatter(dxll[r*columns+c],dzll[r*columns+c])\n",
    "        # ax[r,c].scatter(dyll[r*columns+c][0:110],dzll[r*columns+c][0:110])        \n",
    "        ax[r,c].scatter(dyll[r*columns+c],dxll[r*columns+c])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(index, df['aX'], 'g.', label='x', linestyle='solid', marker=',')\n",
    "# plt.plot(index, df['aY'], 'b.', label='y', linestyle='solid', marker=',')\n",
    "# plt.plot(index, df['aZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
    "# plt.plot(index, vx_list, 'g.', label='x', linestyle='solid', marker=',')\n",
    "# # plt.plot(index, vy_list, 'b.', label='y', linestyle='solid', marker=',')\n",
    "# plt.plot(index, vz_list, 'r.', label='z', linestyle='solid', marker=',')\n",
    "# plt.plot(index, dx_list, 'k.', label='dx', linestyle='solid', marker=',')\n",
    "# # plt.plot(index, dy_list, 'm.', label='dy', linestyle='solid', marker=',')\n",
    "# plt.plot(index, dz_list, 'c.', label='dz', linestyle='solid', marker=',')\n",
    "# plt.title(\"Acceleration\")\n",
    "# plt.xlabel(\"Sample #\")\n",
    "# plt.ylabel(\"Acceleration (G)\")\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(index, df['gX'], 'g.', label='x', linestyle='solid', marker=',')\n",
    "# plt.plot(index, df['gY'], 'b.', label='y', linestyle='solid', marker=',')\n",
    "# plt.plot(index, df['gZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
    "# plt.title(\"Gyroscope\")\n",
    "# plt.xlabel(\"Sample #\")\n",
    "# plt.ylabel(\"Gyroscope (deg/sec)\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264eb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "fig, ax = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        # xi = dyll[r*columns+c]\n",
    "        # xj = dzll[r*columns+c]\n",
    "        # print(xi, \" \" , xj)\n",
    "        # ax[r,c].plot(vxll[r*columns+c], label='x')\n",
    "        ax[r,c].plot(vyll[r*columns+c], label='x')\n",
    "        ax[r,c].plot(vzll[r*columns+c], label='y')\n",
    "        # print(df['aX'][(r*columns+c)*samples:(r*columns+c+1)*samples])\n",
    "        ax[r,c].plot(range(samples),df['aX'][(r*columns+c)*samples:(r*columns+c+1)*samples], label='xa')\n",
    "        # ax[r,c].plot(range(samples),df['aZ'][(r*columns+c)*samples:(r*columns+c+1)*samples], label='xa')\n",
    "        ax[r,c].plot(range(samples),df['aY'][(r*columns+c)*samples:(r*columns+c+1)*samples], label='ya')\n",
    "        ax[r,c].plot(range(samples),df['aZ'][(r*columns+c)*samples:(r*columns+c+1)*samples], label='za')\n",
    "        ax[r,c].legend()\n",
    "        # ax[r,c].scatter(dxll[r*columns+c],dzll[r*columns+c])\n",
    "        # ax[r,c].scatter(dyll[r*columns+c],dzll[r*columns+c])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].scatter(dx_list, dz_list)\n",
    "ax[0,1].scatter(dy_list, dz_list)\n",
    "ax[1,0].scatter(dx_list, dz_list)\n",
    "ax[1,1].scatter(dy_list, dz_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37989a-301e-4263-80e2-d850d77288be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c5c64-98b2-4f80-8352-094a57e24f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
    "\n",
    "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
    "# the same random numbers each time the notebook is run\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# the list of gestures that data is available for\n",
    "GESTURES = [\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "]\n",
    "\n",
    "SAMPLES_PER_GESTURE = 416\n",
    "\n",
    "NUM_GESTURES = len(GESTURES)\n",
    "\n",
    "# create a one-hot encoded matrix that is used in the output\n",
    "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# read each csv file and push an input and output\n",
    "for gesture_index in range(NUM_GESTURES):\n",
    "  gesture = GESTURES[gesture_index]\n",
    "  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
    "  \n",
    "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "  \n",
    "  df = pd.read_csv(\"./content/\" + gesture + \".csv\")\n",
    "  \n",
    "  # calculate the number of gesture recordings in the file\n",
    "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
    "  \n",
    "  print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
    "  \n",
    "  for i in range(num_recordings):\n",
    "    tensor = []\n",
    "    for j in range(SAMPLES_PER_GESTURE // 2 + 100):\n",
    "      index = i * SAMPLES_PER_GESTURE + j\n",
    "      # normalize the input data, between 0 to 1:\n",
    "      # - acceleration is between: -4 to +4\n",
    "      # - gyroscope is between: -2000 to +2000\n",
    "      tensor += [\n",
    "          (df['aX'][index] + 4) / 8,\n",
    "          (df['aY'][index] + 4) / 8,\n",
    "          (df['aZ'][index] + 4) / 8,\n",
    "          (df['gX'][index] + 2000) / 4000,\n",
    "          (df['gY'][index] + 2000) / 4000,\n",
    "          (df['gZ'][index] + 2000) / 4000\n",
    "      ]\n",
    "\n",
    "    inputs.append(tensor)\n",
    "    outputs.append(output)\n",
    "    inputs.append(tensor)\n",
    "    outputs.append(output)\n",
    "# convert the list to numpy array\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "print(\"Data set parsing and preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852838e-a38b-415d-a9d4-886f8092e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0df06-749c-434e-ac26-cbb465940db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce447d-e1c5-4f03-a94c-dc90b16ca4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"Data set randomization and splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63a4fc-92ae-4f3d-904e-b7128216879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(inputs_train, outputs_train, epochs=10, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10d097-0699-436e-bfaf-2027881fe565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the size of the graphs. The default size is (6,4).\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(plt.rcParams[\"figure.figsize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293c6f9-526f-4686-a511-88340c259620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the loss again skipping a bit of the start\n",
    "SKIP = 100\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f65474-4a08-441a-8b3d-f00d4a5f0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of mean absolute error\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f86ae7-f32e-4bf6-af89-f18f1ee7b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs_test.shape)\n",
    "print(outputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b548b0-55f8-495c-ad78-4bd4a459f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(inputs_test)\n",
    "# predictions = model.predict(inputs_test[0].reshape(1,1248))\n",
    "# print(predictions[0])\n",
    "# print(outputs_test[0])\n",
    "# print (inputs_test[0])\n",
    "\n",
    "# pd.DataFrame(inputs_test[0]).to_csv(\"test1.h\", sep=',', encoding='utf-8', index=False, header=False)\n",
    "# !echo \"const unsigned char tt[] = {\" > ./tt.h\n",
    "# !cat \"test1.csv\" | xxd -i      >> ./tt.h\n",
    "# !echo \"};\"                              >> ./tt.h\n",
    "\n",
    "# print the predictions and the expected ouputs\n",
    "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
    "# print(\"actual =\\n\", outputs_test)\n",
    "a = np.round(predictions - outputs_test, decimals=0)\n",
    "print(a)\n",
    "# Plot the predictions along with to the test data\n",
    "# plt.clf()\n",
    "# plt.title('Training data predicted vs actual values')\n",
    "# plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
    "# plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b95bed-c0d8-4dbd-a273-d65a02c98a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b006ac-b63a-4e74-8dce-297e7bd643f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > ./content/model.h\n",
    "!cat gesture_model.tflite | xxd -i      >> ./content/model.h\n",
    "!echo \"};\"                              >> ./content/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"./content/model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
    "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
