{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabaf7a-b620-4398-ad21-529b876bfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "# !apt-get -qq install xxd\n",
    "# !pip3 install pandas numpy matplotlib\n",
    "# !pip3 install tensorflow==2.13.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c5c64-98b2-4f80-8352-094a57e24f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import random\n",
    "\n",
    "file_path = \"processed_data/*\"\n",
    "\n",
    "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
    "\n",
    "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
    "# the same random numbers each time the notebook is run\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# the list of gestures that data is available for\n",
    "GESTURES = [\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "    \"c\",\n",
    "    \"d\",\n",
    "    \"e\",\n",
    "    \"f\",\n",
    "    \"g\"\n",
    "]\n",
    "\n",
    "SAMPLES_PER_GESTURE = 120\n",
    "\n",
    "NUM_GESTURES = len(GESTURES)\n",
    "\n",
    "# create a one-hot encoded matrix that is used in the output\n",
    "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "datafiles = glob.glob(file_path)\n",
    "# datafiles.sort()\n",
    "print(datafiles)\n",
    "\n",
    "for datafile in datafiles:\n",
    "    out = []    \n",
    "\n",
    "    tensor = pd.read_csv(datafile)\n",
    "    inputs.append(np.array(tensor.values.ravel()))\n",
    "# np.array(t1.values.ravel())\n",
    "    gesture_index=0\n",
    "    for i in range(NUM_GESTURES):\n",
    "        if datafile[15] == GESTURES[i]:\n",
    "            gesture_index = i\n",
    "    output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "    outputs.append(output)\n",
    "    print (\"processed \", datafile, \"output=\", GESTURES[gesture_index])\n",
    "    \n",
    "\n",
    "# read each csv file and push an input and output\n",
    "# for gesture_index in range(NUM_GESTURES):\n",
    "#   gesture = GESTURES[gesture_index]\n",
    "#   print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
    "  \n",
    "#   output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "  \n",
    "#   df = pd.read_csv(\"./content/\" + gesture + \".csv\")\n",
    "#   df = df.drop('lineno', axis=1)\n",
    "  \n",
    "#   # calculate the number of gesture recordings in the file\n",
    "#   num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
    "  \n",
    "#   print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
    "#   print(df)\n",
    "  \n",
    "#   for i in range(num_recordings):\n",
    "#     tensor = []\n",
    "#     for j in range(SAMPLES_PER_GESTURE ):\n",
    "#       print(\"process \", i , \", \", j)\n",
    "#       index = i * SAMPLES_PER_GESTURE + j\n",
    "#       # normalize the input data, between 0 to 1:\n",
    "#       # - acceleration is between: -4 to +4\n",
    "#       # - gyroscope is between: -2000 to +2000\n",
    "#       tensor += [\n",
    "#           (df['aX'][index] + 4) / 8,\n",
    "#           (df['aY'][index] + 4) / 8,\n",
    "#           (df['aZ'][index] + 4) / 8,\n",
    "#           (df['gX'][index] + 2000) / 4000,\n",
    "#           (df['gY'][index] + 2000) / 4000,\n",
    "#           (df['gZ'][index] + 2000) / 4000\n",
    "#       ]\n",
    "\n",
    "#     inputs.append(tensor)\n",
    "#     outputs.append(output)\n",
    "\n",
    "# convert the list to numpy array\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "print(\"Data set parsing and preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852838e-a38b-415d-a9d4-886f8092e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0df06-749c-434e-ac26-cbb465940db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce447d-e1c5-4f03-a94c-dc90b16ca4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"Data set randomization and splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63a4fc-92ae-4f3d-904e-b7128216879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu')) # relu is used for performance\n",
    "# model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(inputs_train, outputs_train, epochs=200, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10d097-0699-436e-bfaf-2027881fe565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the size of the graphs. The default size is (6,4).\n",
    "plt.rcParams[\"figure.figsize\"] = (5,3)\n",
    "\n",
    "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(plt.rcParams[\"figure.figsize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293c6f9-526f-4686-a511-88340c259620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the loss again skipping a bit of the start\n",
    "SKIP = 100\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f65474-4a08-441a-8b3d-f00d4a5f0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of mean absolute error\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f86ae7-f32e-4bf6-af89-f18f1ee7b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs_test.shape)\n",
    "print(outputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input shape\" , inputs_test.shape)\n",
    "print(type(inputs_test))\n",
    "# print (len(data1))\n",
    "# inputs_test = np.concatenate((inputs_test, [np.array(data1)]), axis=0)\n",
    "# print(\"input shape\" , inputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"processed_data/a_1.dat\")\n",
    "# print(t1)\n",
    "single_sample = np.array(t1.values.ravel())\n",
    "single_sample1 = (t1.melt().value.tolist())\n",
    "print(type(single_sample))\n",
    "prediction = model.predict(np.expand_dims(single_sample, axis=0))\n",
    "prediction1 = model.predict(np.expand_dims(single_sample1, axis=0))\n",
    "\n",
    "# formatted_numbers = [\"{:.2f}\".format(number) for number in prediction[0]]\n",
    "\n",
    "# print(\"Formatted Numbers:\", formatted_numbers)\n",
    "# print(\"Prediction:\", prediction)\n",
    "\n",
    "print(\"predictions =\\n\", np.round(prediction, decimals=3), np.round(prediction1, decimals=3))\n",
    "# print(single_sample)\n",
    "# print(single_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdde0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"processed_data/a_1.dat\")\n",
    "# [np.array(t1.values.ravel())]\n",
    "\n",
    "# inputs_test = np.concatenate((inputs_test, [np.array(t1.values.ravel())]), axis=0)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b548b0-55f8-495c-ad78-4bd4a459f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(inputs_test)\n",
    "print(\"pred shape\" , predictions.shape)\n",
    "# predictions = model.predict(inputs_test[0].reshape(1,1248))\n",
    "# print(predictions[0])\n",
    "# print(outputs_test[0])\n",
    "# print (inputs_test[0])\n",
    "\n",
    "# pd.DataFrame(inputs_test[0]).to_csv(\"test1.h\", sep=',', encoding='utf-8', index=False, header=False)\n",
    "# !echo \"const unsigned char tt[] = {\" > ./tt.h\n",
    "# !cat \"test1.csv\" | xxd -i      >> ./tt.h\n",
    "# !echo \"};\"                              >> ./tt.h\n",
    "\n",
    "# print the predictions and the expected ouputs\n",
    "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
    "\n",
    "print(\"actual =\\n\", outputs_test)\n",
    "a = np.round(predictions - outputs_test, decimals=0)\n",
    "print(a)\n",
    "# Plot the predictions along with to the test data\n",
    "# plt.clf()\n",
    "# plt.title('Training data predicted vs actual values')\n",
    "# plt.plot( outputs_test, 'b.', label='Actual')\n",
    "# plt.plot( predictions, 'r.', label='Predicted')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# accuracy = accuracy_score(outputs_test, predictions)\n",
    "# precision = precision_score(outputs_test, predictions)\n",
    "# recall = recall_score(outputs_test, predictions)\n",
    "# f1 = f1_score(outputs_test, predictions)\n",
    "# conf_matrix = confusion_matrix(outputs_test, predictions)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1-Score: {f1}\")\n",
    "# print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84406d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(outputs_test, predictions)\n",
    "# plt.xlabel(\"True Values\")\n",
    "# plt.ylabel(\"Predictions\")\n",
    "# plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "r2 = r2_score(outputs_test, predictions)\n",
    "print(\"r2=\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666497c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions[0]+0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710498bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, 'my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b95bed-c0d8-4dbd-a273-d65a02c98a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b006ac-b63a-4e74-8dce-297e7bd643f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > ./content/model.h\n",
    "!cat gesture_model.tflite | xxd -i      >> ./content/model.h\n",
    "!echo \"};\"                              >> ./content/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"./content/model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
    "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
