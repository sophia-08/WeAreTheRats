{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabaf7a-b620-4398-ad21-529b876bfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "# !apt-get -qq install xxd\n",
    "# !pip3 install pandas numpy matplotlib\n",
    "# !pip3 install tensorflow==2.13.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb579b",
   "metadata": {},
   "source": [
    "With model '''\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(inputs_train, outputs_train, epochs=200, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "'''\n",
    "\n",
    "result:<br>\n",
    "tests by letter:  [24 21 27 27 17 25 34 24 29 22 26 35 22 35 17 27 28 25 23 18 21 22 30 25 32 31]<br>\n",
    "wrong predict by letter:  [ 5  3  4  4  0  6 13  0  1  2  2  6  2 12  3  5  6  7  5  4  3  2  7 11 12  5]<br>\n",
    "wrong rate:  [0.21 0.14 0.15 0.15 0.   0.24 0.38 0.   0.03 0.09 0.08 0.17 0.09 0.34\n",
    " 0.18 0.19 0.21 0.28 0.22 0.22 0.14 0.09 0.23 0.44 0.38 0.16]<br>\n",
    "\n",
    "\n",
    "add another layer<br>\n",
    "tests by letter:  [24 21 27 27 17 25 34 24 29 22 26 35 22 35 17 27 28 25 23 18 21 22 30 25\n",
    " 32 31]<br>\n",
    "wrong predict by letter:  [ 7  6  9  2  0  5 14 11 10  8  1 20  6 17  7 13  2  7  3  6  6  4  8  4\n",
    " 17  3]<br>\n",
    "wrong rate:  [0.29 0.29 0.33 0.07 0.   0.2  0.41 0.46 0.34 0.36 0.04 0.57 0.27 0.49\n",
    " 0.41 0.48 0.07 0.28 0.13 0.33 0.29 0.18 0.27 0.16 0.53 0.1 ]<br>\n",
    " r2 score 0.73 <br>\n",
    "\n",
    " increase epoches to 500, r2 score 0.55, error start increast around 150-200, <br>\n",
    "\n",
    " use two layer, first layer 120 tensors, second 60 tensors. <br>\n",
    " tests by letter:  [24 21 27 27 17 25 34 24 29 22 26 35 22 35 17 27 28 25 23 18 21 22 30 25\n",
    " 32 31] <br>\n",
    "wrong predict by letter:  [ 2  5  4  2  0  2  6 16  3  2  4  7 10 11  4  3  4  7  0  2  5  1 10  6\n",
    " 10  4] <br>\n",
    "wrong rate:  [0.08 0.24 0.15 0.07 0.   0.08 0.18 0.67 0.1  0.09 0.15 0.2  0.45 0.31\n",
    " 0.24 0.11  0.14 0.28 0.   0.11 0.24 0.05 0.33 0.24 0.31 0.13] <br>\n",
    "\n",
    " r2 score 0.82, Model is 383556 bytes <br>\n",
    " Sketch uses 766672 bytes (94%) of program storage space. Maximum is 811008 bytes.<br>\n",
    "Global variables use 59936 bytes (25%) of dynamic memory, leaving 177632 bytes for local variables. Maximum is 237568 bytes. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c5c64-98b2-4f80-8352-094a57e24f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import random\n",
    "\n",
    "file_path = \"processed_data/*\"\n",
    "\n",
    "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
    "\n",
    "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
    "# the same random numbers each time the notebook is run\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# the list of gestures that data is available for\n",
    "GESTURES = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "SAMPLES_PER_GESTURE = 120\n",
    "\n",
    "NUM_GESTURES = 26\n",
    "\n",
    "# create a one-hot encoded matrix that is used in the output\n",
    "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "datafiles = glob.glob(file_path)\n",
    "# datafiles.sort()\n",
    "print(\"total files\", len(datafiles))\n",
    "\n",
    "for datafile in datafiles:\n",
    "    out = []    \n",
    "\n",
    "    tensor = pd.read_csv(datafile)\n",
    "    inputs.append(np.array(tensor.values.ravel()))\n",
    "\n",
    "    gesture_index=0\n",
    "    for i in range(NUM_GESTURES):\n",
    "        if datafile[15] == GESTURES[i]:\n",
    "            gesture_index = i\n",
    "    output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "    outputs.append(output)\n",
    "    # print (\"processed \", datafile, \"output=\", GESTURES[gesture_index])\n",
    "    \n",
    "# convert the list to numpy array\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "print (\"input shape: \", inputs.shape, \" output shape\", outputs.shape)\n",
    "\n",
    "print(\"Data set parsing and preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce447d-e1c5-4f03-a94c-dc90b16ca4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"Data set randomization and splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63a4fc-92ae-4f3d-904e-b7128216879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(120, activation='relu')) # relu is used for performance\n",
    "# model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(60, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10d097-0699-436e-bfaf-2027881fe565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the size of the graphs. The default size is (6,4).\n",
    "plt.rcParams[\"figure.figsize\"] = (5,3)\n",
    "\n",
    "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(plt.rcParams[\"figure.figsize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293c6f9-526f-4686-a511-88340c259620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the loss again skipping a bit of the start\n",
    "SKIP = 100\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f65474-4a08-441a-8b3d-f00d4a5f0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of mean absolute error\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input shape\" , inputs_test.shape)\n",
    "print(type(inputs_test))\n",
    "# print (len(data1))\n",
    "# inputs_test = np.concatenate((inputs_test, [np.array(data1)]), axis=0)\n",
    "# print(\"input shape\" , inputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"processed_data/a_1.dat\")\n",
    "# print(t1)\n",
    "single_sample = np.array(t1.values.ravel())\n",
    "# single_sample1 = (t1.melt().value.tolist())\n",
    "print(type(single_sample))\n",
    "prediction = model.predict(np.expand_dims(single_sample, axis=0))\n",
    "# prediction1 = model.predict(np.expand_dims(single_sample1, axis=0))\n",
    "\n",
    "# formatted_numbers = [\"{:.2f}\".format(number) for number in prediction[0]]\n",
    "\n",
    "# print(\"Formatted Numbers:\", formatted_numbers)\n",
    "# print(\"Prediction:\", prediction)\n",
    "\n",
    "print(\"predictions =\\n\", np.round(prediction, decimals=3))\n",
    "# print(single_sample)\n",
    "# print(single_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdde0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = pd.read_csv(\"processed_data/a_1.dat\")\n",
    "# [np.array(t1.values.ravel())]\n",
    "\n",
    "# inputs_test = np.concatenate((inputs_test, [np.array(t1.values.ravel())]), axis=0)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b548b0-55f8-495c-ad78-4bd4a459f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(inputs_test)\n",
    "print(\"pred shape\" , predictions.shape)\n",
    "# predictions = model.predict(inputs_test[0].reshape(1,1248))\n",
    "# print(predictions[0])\n",
    "# print(outputs_test[0])\n",
    "# print (inputs_test[0])\n",
    "\n",
    "# pd.DataFrame(inputs_test[0]).to_csv(\"test1.h\", sep=',', encoding='utf-8', index=False, header=False)\n",
    "# !echo \"const unsigned char tt[] = {\" > ./tt.h\n",
    "# !cat \"test1.csv\" | xxd -i      >> ./tt.h\n",
    "# !echo \"};\"                              >> ./tt.h\n",
    "\n",
    "# print the predictions and the expected ouputs\n",
    "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
    "\n",
    "print(\"actual =\\n\", outputs_test)\n",
    "a = np.round(predictions - outputs_test, decimals=0)\n",
    "print(a)\n",
    "# Plot the predictions along with to the test data\n",
    "# plt.clf()\n",
    "# plt.title('Training data predicted vs actual values')\n",
    "# plt.plot( outputs_test, 'b.', label='Actual')\n",
    "# plt.plot( predictions, 'r.', label='Predicted')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs_test[:, 0].dtype)\n",
    "print(predictions[:, 0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7bbaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = (predictions + 0.5).astype(int)\n",
    "# pre\n",
    "a = pre-outputs_test\n",
    "tests_by_letter = outputs_test.astype(bool).sum(axis=0)\n",
    "print(\"tests by letter: \", tests_by_letter)\n",
    "wrong_predict_by_letter = a.astype(bool).sum(axis=0)\n",
    "print(\"wrong predict by letter: \", wrong_predict_by_letter)\n",
    "print(\"wrong rate: \", np.round(wrong_predict_by_letter/tests_by_letter, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# accuracy = accuracy_score(outputs_test, predictions)\n",
    "# precision = precision_score(outputs_test, predictions)\n",
    "# recall = recall_score(outputs_test, predictions)\n",
    "# f1 = f1_score(outputs_test, predictions)\n",
    "# conf_matrix = confusion_matrix(outputs_test, predictions)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1-Score: {f1}\")\n",
    "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "# Initialize an array to store accuracy for each class\n",
    "\n",
    "# class_accuracies = []\n",
    "\n",
    "# # Iterate over each class (assuming axis 1 represents classes)\n",
    "# for class_index in range(26):\n",
    "#     true_labels_class = outputs_test[:, class_index]\n",
    "#     predicted_labels_class = pre[:, class_index]\n",
    "#     accuracy = accuracy_score(true_labels_class, predicted_labels_class)\n",
    "#     class_accuracies.append(accuracy)\n",
    "\n",
    "# # Calculate micro-average accuracy (overall accuracy)\n",
    "# micro_average_accuracy = accuracy_score(outputs_test, predictions)\n",
    "\n",
    "# # Calculate macro-average accuracy (average accuracy across classes)\n",
    "# macro_average_accuracy = sum(class_accuracies) / len(class_accuracies)\n",
    "\n",
    "# # Print individual class accuracies and the macro/micro averages\n",
    "# for class_index, accuracy in enumerate(class_accuracies):\n",
    "#     print(f\"Class {class_index}: Accuracy = {accuracy}\")\n",
    "\n",
    "# print(f\"Micro-average accuracy: {micro_average_accuracy}\")\n",
    "# print(f\"Macro-average accuracy: {macro_average_accuracy}\")\n",
    "# In the code above:\n",
    "\n",
    "# We iterate over each class, treating it as a binary classification problem by selecting the true labels and predicted labels for that class.\n",
    "# We calculate the accuracy for each class separately and store it in the class_accuracies list.\n",
    "# We compute the micro-average accuracy, which is the overall accuracy across all samples and classes.\n",
    "# We compute the macro-average accuracy, which is the average accuracy across all classes.\n",
    "# This approach allows you to evaluate the performance of your multi-class classification model for each individual class and provides overall accuracy metrics as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84406d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(outputs_test, predictions)\n",
    "# plt.xlabel(\"True Values\")\n",
    "# plt.ylabel(\"Predictions\")\n",
    "# plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "r2 = r2_score(outputs_test, predictions)\n",
    "print(\"r2=\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666497c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions[0]+0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710498bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, 'my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b95bed-c0d8-4dbd-a273-d65a02c98a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b006ac-b63a-4e74-8dce-297e7bd643f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > ./content/model.h\n",
    "!cat gesture_model.tflite | xxd -i      >> ./content/model.h\n",
    "!echo \"};\"                              >> ./content/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"./content/model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
    "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming 'y_true' contains the true labels and 'y_pred' contains the predicted labels\n",
    "f1 = f1_score(outputs_test, pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
